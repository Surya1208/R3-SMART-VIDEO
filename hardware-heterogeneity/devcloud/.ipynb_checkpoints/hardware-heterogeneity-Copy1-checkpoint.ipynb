{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Intel® Distribution of OpenVINO™ toolkit hetero plugin\n",
    "\n",
    "\n",
    "    \n",
    "This example shows how to use hetero plugin to define preferences to run different network layers on different hardware types. Here, we will use the command line option to define hetero plugin usage where the layer distribution is already defined. However, hetero plugin also allows developers to customize distribution of layers execution on different hardware by specifying it in the application code.\n",
    "\n",
    "## Car detection tutorial example\n",
    "\n",
    "### 1. Importing dependencies, Setting the Environment variables and Generate the IR files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import os\n",
    "import time\n",
    "import sys                                     \n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path().resolve().parent.parent))\n",
    "from demoTools.demoutils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[setupvars.sh] OpenVINO environment initialized\r\n"
     ]
    }
   ],
   "source": [
    "!/opt/intel/openvino/bin/setupvars.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###############|| Downloading topologies ||###############\n",
      "\n",
      "========= Downloading models/object_detection/common/mobilenet-ssd/caffe/mobilenet-ssd.prototxt\n",
      "... 100%, 28 KB, 60279 KB/s, 0 seconds passed\n",
      "\n",
      "========= Downloading models/object_detection/common/mobilenet-ssd/caffe/mobilenet-ssd.caffemodel\n",
      "... 100%, 22605 KB, 19274 KB/s, 1 seconds passed\n",
      "\n",
      "\n",
      "###############|| Post processing ||###############\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name mobilenet-ssd -o models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/home/u28225/Reference-samples/18oct/smart-video-workshop/hardware-heterogeneity/devcloud/models/object_detection/common/mobilenet-ssd/caffe/mobilenet-ssd.caffemodel\n",
      "\t- Path for generated IR: \t/home/u28225/Reference-samples/18oct/smart-video-workshop/hardware-heterogeneity/devcloud/models/object_detection/common/mobilenet-ssd/FP32/\n",
      "\t- IR output name: \tmobilenet-ssd\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \tNot specified, inherited from the model\n",
      "\t- Mean values: \t[127,127,127]\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \t256.0\n",
      "\t- Precision of IR: \tFP32\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tFalse\n",
      "\t- Reverse input channels: \tFalse\n",
      "Caffe specific parameters:\n",
      "\t- Enable resnet optimization: \tTrue\n",
      "\t- Path to the Input prototxt: \t/home/u28225/Reference-samples/18oct/smart-video-workshop/hardware-heterogeneity/devcloud/models/object_detection/common/mobilenet-ssd/caffe/mobilenet-ssd.prototxt\n",
      "\t- Path to CustomLayersMapping.xml: \tDefault\n",
      "\t- Path to a mean file: \tNot specified\n",
      "\t- Offsets for a mean file: \tNot specified\n",
      "Model Optimizer version: \t2019.1.0-341-gc9b66a2\n",
      "\n",
      "[ SUCCESS ] Generated IR model.\n",
      "[ SUCCESS ] XML file: /home/u28225/Reference-samples/18oct/smart-video-workshop/hardware-heterogeneity/devcloud/models/object_detection/common/mobilenet-ssd/FP32/mobilenet-ssd.xml\n",
      "[ SUCCESS ] BIN file: /home/u28225/Reference-samples/18oct/smart-video-workshop/hardware-heterogeneity/devcloud/models/object_detection/common/mobilenet-ssd/FP32/mobilenet-ssd.bin\n",
      "[ SUCCESS ] Total execution time: 4.70 seconds. \n"
     ]
    }
   ],
   "source": [
    "! python3 /opt/intel/openvino/deployment_tools/model_optimizer/mo_caffe.py --input_model models/object_detection/common/mobilenet-ssd/caffe/mobilenet-ssd.caffemodel -o models/object_detection/common/mobilenet-ssd/FP32/ --scale 256 --mean_values [127,127,127]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 2. Run the car detection tutorial with hetero plugin\n",
    "\n",
    "\n",
    "#### Create Job Script \n",
    "\n",
    "We will run the workload on several DevCloud's edge compute nodes. We will send work to the edge compute nodes by submitting jobs into a queue. For each job, we will specify the type of the edge compute server that must be allocated for the job.\n",
    "\n",
    "To pass the specific variables to the Python code, we will use following arguments:\n",
    "\n",
    "* `-f`&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;location of the optimized models XML\n",
    "* `-i`&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;location of the input video\n",
    "* `-r`&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;output directory\n",
    "* `-d`&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;hardware device type (CPU, GPU, MYRIAD, HDDL or HETERO:FPGA,CPU)\n",
    "* `-n`&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;number of infer requests\n",
    "\n",
    "The job file will be executed directly on the edge compute node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting object_detection_job.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile object_detection_job.sh\n",
    "\n",
    "# The default path for the job is your home directory, so we change directory to where the files are.\n",
    "cd $PBS_O_WORKDIR\n",
    "OUTPUT_FILE=$1\n",
    "DEVICE=$2\n",
    "FP_MODEL=$3\n",
    "# Object detection script writes output to a file inside a directory. We make sure that this directory exists.\n",
    "#  The output directory is the first argument of the bash script\n",
    "mkdir -p $OUTPUT_FILE\n",
    "ROIFILE=$OUTPUT_FILE/ROIs.txt\n",
    "OVIDEO=$OUTPUT_FILE/output.mp4\n",
    "\n",
    "# Running the object detection code\n",
    "SAMPLEPATH=$PBS_O_WORKDIR\n",
    "./tutorial1 -i cars_1900.mp4 \\\n",
    "            -m models/object_detection/common/mobilenet-ssd/$FP_MODEL/mobilenet-ssd.xml \\\n",
    "            -d $DEVICE \\\n",
    "            -o $OUTPUT_FILE\\\n",
    "            -fr 3000 \n",
    "\n",
    "# Converting the text output to a video\n",
    "./ROI_writer -i cars_1900.mp4 \\\n",
    "             -o $OUTPUT_FILE \\\n",
    "             -ROIfile $ROIFILE \\\n",
    "             -l pascal_voc_classes.txt \\\n",
    "             -r 2.0 # output in half res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Prioritizing running on GPU first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"VIDEO\"] = \"cars_1900.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting a job to an edge compute node with an Intel Core CPU...\n",
      "62871.c003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbcaad26592940f99c38b1f16eedbeec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Inference', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd550124061e462a9fb515282fa26800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Rendering', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Submitting a job to an edge compute node with an Intel Core CPU...\")\n",
    "#Submit job to the queue\n",
    "job_id_core = !qsub object_detection_job.sh -l nodes=1:tank-870:i5-6500te -F \"results/GPU HETERO:GPU,CPU FP32\" -N obj_det_core\n",
    "print(job_id_core[0])\n",
    "#Progress indicators\n",
    "if job_id_core:\n",
    "    progressIndicator('results/GPU', 'i_progress_'+job_id_core[0]+'.txt', \"Inference\", 0, 100)\n",
    "    progressIndicator('results/GPU', 'v_progress_'+job_id_core[0]+'.txt', \"Rendering\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    \n",
    "#### b) Prioritizing running on CPU first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting a job to an edge compute node with an Intel Core CPU...\n",
      "62873.c003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccc76a4e8264432f9df33dcdfb449bf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Inference', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00dbe73d31b94751ae3e2e638e3db02d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Rendering', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Submitting a job to an edge compute node with an Intel Core CPU...\")\n",
    "#Submit job to the queue\n",
    "job_id_core = !qsub object_detection_job.sh -l nodes=1:tank-870:i5-6500te -F \"results/Core HETERO:CPU,GPU FP32\" -N obj_det_core\n",
    "print(job_id_core[0])\n",
    "#Progress indicators\n",
    "if job_id_core:\n",
    "    progressIndicator('results/Core', 'i_progress_'+job_id_core[0]+'.txt', \"Inference\", 0, 100)\n",
    "    progressIndicator('results/Core', 'v_progress_'+job_id_core[0]+'.txt', \"Rendering\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Observe the performance time required to process each frame by Inference Engine. For this particular example, inference ran faster when prioritized for CPU as oppose to when GPU was the first priority.\n",
    "\n",
    " \n",
    "## Inference Engine classification sample\n",
    "\n",
    "\n",
    "Intel® Distribution of OpenVINO™ toolkit install folder (/opt/intel/openvino) includes various samples for developers to understand how Inference Engine APIs can be used. These samples have -pc flag implmented which shows per topology layer performance report. This will allow to see which layers are running on which hardware. We will run a very basic classification sample as an example in this section. We will provide car image as input to the classification sample. The output will be object labels with confidence numbers.\n",
    "\n",
    "### 1. First, get the classification model and convert that to IR using Model Optimizer\n",
    "\n",
    "For this example, we will use squeezenet model downloaded with the model downloader script while setting up the OS for the workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###############|| Downloading topologies ||###############\n",
      "\n",
      "========= Downloading models/classification/squeezenet/1.1/caffe/squeezenet1.1.prototxt\n",
      "... 100%, 9 KB, 25256 KB/s, 0 seconds passed\n",
      "\n",
      "========= Downloading models/classification/squeezenet/1.1/caffe/squeezenet1.1.caffemodel\n",
      "... 100%, 4834 KB, 714 KB/s, 6 seconds passed\n",
      "\n",
      "\n",
      "###############|| Post processing ||###############\n",
      "\n",
      "========= Changing input dimensions in squeezenet1.1.prototxt =========\n"
     ]
    }
   ],
   "source": [
    "! /opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name squeezenet1.1 -o models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/home/u28225/Reference-samples/18oct/smart-video-workshop/hardware-heterogeneity/devcloud/models/classification/squeezenet/1.1/caffe/squeezenet1.1.caffemodel\n",
      "\t- Path for generated IR: \t/home/u28225/Reference-samples/18oct/smart-video-workshop/hardware-heterogeneity/devcloud/models/squeezenet/FP32/\n",
      "\t- IR output name: \tsqueezenet1.1\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \tNot specified, inherited from the model\n",
      "\t- Mean values: \tNot specified\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP32\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tFalse\n",
      "\t- Reverse input channels: \tFalse\n",
      "Caffe specific parameters:\n",
      "\t- Enable resnet optimization: \tTrue\n",
      "\t- Path to the Input prototxt: \t/home/u28225/Reference-samples/18oct/smart-video-workshop/hardware-heterogeneity/devcloud/models/classification/squeezenet/1.1/caffe/squeezenet1.1.prototxt\n",
      "\t- Path to CustomLayersMapping.xml: \tDefault\n",
      "\t- Path to a mean file: \tNot specified\n",
      "\t- Offsets for a mean file: \tNot specified\n",
      "Model Optimizer version: \t2019.1.0-341-gc9b66a2\n",
      "\n",
      "[ SUCCESS ] Generated IR model.\n",
      "[ SUCCESS ] XML file: /home/u28225/Reference-samples/18oct/smart-video-workshop/hardware-heterogeneity/devcloud/models/squeezenet/FP32/squeezenet1.1.xml\n",
      "[ SUCCESS ] BIN file: /home/u28225/Reference-samples/18oct/smart-video-workshop/hardware-heterogeneity/devcloud/models/squeezenet/FP32/squeezenet1.1.bin\n",
      "[ SUCCESS ] Total execution time: 3.26 seconds. \n"
     ]
    }
   ],
   "source": [
    "! /opt/intel/openvino/deployment_tools/model_optimizer/mo_caffe.py --input_model models/classification/squeezenet/1.1/caffe/squeezenet1.1.caffemodel -o models/squeezenet/FP32/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To display labels after classifictaion, you will need a labels file for the SqueezeNet* model. Get the available labels file from demo directory to your working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /opt/intel/openvino/deployment_tools/demo/squeezenet1.1.labels models/squeezenet/FP32/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###############|| Downloading topologies ||###############\n",
      "\n",
      "========= Downloading models/object_detection/common/mobilenet-ssd/caffe/mobilenet-ssd.prototxt\n",
      "... 100%, 28 KB, 63151 KB/s, 0 seconds passed\n",
      "\n",
      "========= Downloading models/object_detection/common/mobilenet-ssd/caffe/mobilenet-ssd.caffemodel\n",
      "... 100%, 22605 KB, 22484 KB/s, 1 seconds passed\n",
      "\n",
      "\n",
      "###############|| Post processing ||###############\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name mobilenet-ssd -o models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/home/u28225/Reference-samples/18oct/smart-video-workshop/hardware-heterogeneity/devcloud/models/object_detection/common/mobilenet-ssd/caffe/mobilenet-ssd.caffemodel\n",
      "\t- Path for generated IR: \t/home/u28225/Reference-samples/18oct/smart-video-workshop/hardware-heterogeneity/devcloud/models/object_detection/common/mobilenet-ssd/FP32/\n",
      "\t- IR output name: \tmobilenet-ssd\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \tNot specified, inherited from the model\n",
      "\t- Mean values: \t[127,127,127]\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \t256.0\n",
      "\t- Precision of IR: \tFP32\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tFalse\n",
      "\t- Reverse input channels: \tFalse\n",
      "Caffe specific parameters:\n",
      "\t- Enable resnet optimization: \tTrue\n",
      "\t- Path to the Input prototxt: \t/home/u28225/Reference-samples/18oct/smart-video-workshop/hardware-heterogeneity/devcloud/models/object_detection/common/mobilenet-ssd/caffe/mobilenet-ssd.prototxt\n",
      "\t- Path to CustomLayersMapping.xml: \tDefault\n",
      "\t- Path to a mean file: \tNot specified\n",
      "\t- Offsets for a mean file: \tNot specified\n",
      "Model Optimizer version: \t2019.1.0-341-gc9b66a2\n",
      "\n",
      "[ SUCCESS ] Generated IR model.\n",
      "[ SUCCESS ] XML file: /home/u28225/Reference-samples/18oct/smart-video-workshop/hardware-heterogeneity/devcloud/models/object_detection/common/mobilenet-ssd/FP32/mobilenet-ssd.xml\n",
      "[ SUCCESS ] BIN file: /home/u28225/Reference-samples/18oct/smart-video-workshop/hardware-heterogeneity/devcloud/models/object_detection/common/mobilenet-ssd/FP32/mobilenet-ssd.bin\n",
      "[ SUCCESS ] Total execution time: 6.60 seconds. \n"
     ]
    }
   ],
   "source": [
    "! python3 /opt/intel/openvino/deployment_tools/model_optimizer/mo_caffe.py --input_model models/object_detection/common/mobilenet-ssd/caffe/mobilenet-ssd.caffemodel -o models/object_detection/common/mobilenet-ssd/FP32/ --scale 256 --mean_values [127,127,127]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will us the [car_1.bmp](car_1.bmp) image to run our classification job as described in the next steps. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    \n",
    "### 2. Run classification sample with hetero plugin, prioritizing running on GPU first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting classification_job.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile classification_job.sh\n",
    "ME=`basename $0`\n",
    "\n",
    "DEVICE=$2\n",
    "\n",
    "# Object detection script writes output to a file inside a directory. We make sure that this directory exists.\n",
    "# The output directory is the first argument of the bash script\n",
    "while getopts 'd:f:i:r:n:?' OPTION; do\n",
    "    case \"$OPTION\" in\n",
    "    d)\n",
    "        DEVICE=$OPTARG\n",
    "        echo \"$ME is using device $OPTARG\"\n",
    "      ;;\n",
    "\n",
    "    f)\n",
    "        FP_MODEL=$OPTARG\n",
    "        echo \"$ME is using floating point model $OPTARG\"\n",
    "      ;;\n",
    "\n",
    "    i)\n",
    "        INPUT_FILE=$OPTARG\n",
    "        echo \"$ME is using input file $OPTARG\"\n",
    "      ;;\n",
    "    r)\n",
    "        RESULTS_BASE=$OPTARG\n",
    "        echo \"$ME is using results base $OPTARG\"\n",
    "      ;;\n",
    "    n)\n",
    "        NUM_INFER_REQS=$OPTARG\n",
    "        echo \"$ME is running $OPTARG inference requests\"\n",
    "      ;;\n",
    "    esac  \n",
    "done\n",
    "\n",
    "# The default path for the job is your home directory, so we change directory to where the files are.\n",
    "cd $PBS_O_WORKDIR\n",
    "\n",
    "#NN_MODEL=\"mobilenet-ssd.xml\"\n",
    "RESULTS_PATH=\"${RESULTS_BASE}\"\n",
    "#mkdir -p $RESULTS_PATH\n",
    "echo \"$ME is using results path $RESULTS_PATH\"\n",
    "\n",
    "if [ \"$DEVICE\" == \"HETERO:FPGA,CPU\" ]; then\n",
    "    # Environment variables and compilation for edge compute nodes with FPGAs\n",
    "    export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/opt/altera/aocl-pro-rte/aclrte-linux64/\n",
    "    # Environment variables and compilation for edge compute nodes with FPGAs\n",
    "    source /opt/fpga_support_files/setup_env.sh\n",
    "    aocl program acl0 /opt/intel/openvino/bitstreams/a10_vision_design_bitstreams/2019R1_PL1_FP11_MobileNet_Clamp.aocx\n",
    "fi\n",
    "    \n",
    "# Running the object detection code\n",
    "#SAMPLEPATH=$PBS_O_WORKDIR\n",
    "./object_detection_demo_ssd_async        -i cars_1900.mp4 \\\n",
    "                                            -m models/object_detection/common/mobilenet-ssd/FP32/mobilenet-ssd.xml \\\n",
    "                                            -d $DEVICE   \\\n",
    "                                            -pc\n",
    "\n",
    "                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62896.c003\n",
      "\n",
      "########################################################################\n",
      "#      Date:           Wed Oct 23 00:07:05 PDT 2019\n",
      "#    Job ID:           62896.c003\n",
      "#      User:           u28225\n",
      "# Resources:           neednodes=1:idc001skl:intel-hd-530,nodes=1:idc001skl:intel-hd-530,walltime=01:00:00\n",
      "########################################################################\n",
      "\n",
      "[setupvars.sh] OpenVINO environment initialized\n",
      "62896.c003.SC is using results path \n",
      "InferenceEngine: \n",
      "\tAPI version ............ 1.6\n",
      "\tBuild .................. custom_releases/2019/R1_c9b66a26e4d65bb986bb740e73f58c6e9e84c7c2\n",
      "[ INFO ] Parsing input parameters\n",
      "[ INFO ] Reading input\n",
      "[ INFO ] Loading plugin\n",
      "\n",
      "\tAPI version ............ 1.6\n",
      "\tBuild .................. heteroPlugin\n",
      "\tDescription ....... heteroPlugin\n",
      "[ INFO ] Loading network files\n",
      "\n",
      "########################################################################\n",
      "# End of output for job 62896.c003\n",
      "# Date: Wed Oct 23 00:07:12 PDT 2019\n",
      "########################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Submit job to the queue\n",
    "job_id_gpu = !qsub classification_job.sh -l nodes=1:idc001skl:intel-hd-530 -F \"results/GPU HETERO:GPU,CPU FP32\" -N obj_det_gpu \n",
    "print(job_id_gpu[0]) \n",
    "while True:\n",
    "    var=job_id_gpu[0].split(\".\")\n",
    "    file=\"obj_det_gpu.o\"+var[0]\n",
    "    if os.path.isfile(file): \n",
    "        ! cat $file\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "After the execution, You should get the performance counters output as in the screenshot below:-\n",
    "\n",
    "\n",
    "<img src='gpu.png'>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    \n",
    "### 3. Now, run with CPU first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62876.c003\n",
      "\n",
      "########################################################################\n",
      "#      Date:           Tue Oct 22 22:54:33 PDT 2019\n",
      "#    Job ID:           62876.c003\n",
      "#      User:           u28225\n",
      "# Resources:           neednodes=1:idc001skl:intel-hd-530,nodes=1:idc001skl:intel-hd-530,walltime=01:00:00\n",
      "########################################################################\n",
      "\n",
      "[setupvars.sh] OpenVINO environment initialized\n",
      "62876.c003.SC is using results path \n",
      "InferenceEngine: \n",
      "\tAPI version ............ 1.6\n",
      "\tBuild .................. custom_releases/2019/R1_c9b66a26e4d65bb986bb740e73f58c6e9e84c7c2\n",
      "[ INFO ] Parsing input parameters\n",
      "[ INFO ] Reading input\n",
      "[ INFO ] Loading plugin\n",
      "\n",
      "\tAPI version ............ 1.6\n",
      "\tBuild .................. heteroPlugin\n",
      "\tDescription ....... heteroPlugin\n",
      "[ INFO ] Loading network files\n",
      "[ INFO ] Batch size is forced to  1.\n",
      "[ INFO ] Checking that the inputs are as the demo expects\n",
      "[ INFO ] Checking that the outputs are as the demo expects\n",
      "\n",
      "########################################################################\n",
      "# End of output for job 62876.c003\n",
      "# Date: Tue Oct 22 22:54:40 PDT 2019\n",
      "########################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Submit job to the queue\n",
    "job_id_cpu = !qsub classification_job.sh -l nodes=1:idc001skl:intel-hd-530 -F \"results/GPU HETERO:CPU,GPU FP32\" -N obj_det_cpu\n",
    "print(job_id_cpu[0]) \n",
    "while True:\n",
    "    var=job_id_cpu[0].split(\".\")\n",
    "    file=\"obj_det_cpu.o\"+var[0]\n",
    "    if os.path.isfile(file): \n",
    "        ! cat $file\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "After the execution, You should get the performance counters output as in the screenshot below:-\n",
    "\n",
    "\n",
    "<img src='cpu.png'>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Ubuntu)",
   "language": "python",
   "name": "c003-python_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
